{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilvanaJ90/usergioarboleda-bootcamp_IA/blob/main/Tutorial_Procesar_Datos_Tensor_Flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d49e1b4-87ad-4a0d-abb8-10b708071c4d",
      "metadata": {
        "id": "3d49e1b4-87ad-4a0d-abb8-10b708071c4d"
      },
      "source": [
        "# Cargar y Preprocesar Datos con TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOjvRZBMTtwX"
      },
      "id": "iOjvRZBMTtwX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e860d39c-4680-4a87-a1c1-0589d70c820a",
      "metadata": {
        "id": "e860d39c-4680-4a87-a1c1-0589d70c820a"
      },
      "outputs": [],
      "source": [
        "#numpy y OS\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5dcad5-f32e-4efd-ad81-c79544c2a33c",
      "metadata": {
        "id": "4c5dcad5-f32e-4efd-ad81-c79544c2a33c"
      },
      "outputs": [],
      "source": [
        "# Scikit Learn\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3422375-caf9-4882-9645-c39007e9f52e",
      "metadata": {
        "id": "b3422375-caf9-4882-9645-c39007e9f52e"
      },
      "outputs": [],
      "source": [
        "# Tensorflow y Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09458ca5-601e-4d67-a659-b1430f75dae7",
      "metadata": {
        "id": "09458ca5-601e-4d67-a659-b1430f75dae7"
      },
      "outputs": [],
      "source": [
        "#Semillas a 42\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678e543f-db52-4d8f-a5d5-07b5b4aad74d",
      "metadata": {
        "id": "678e543f-db52-4d8f-a5d5-07b5b4aad74d"
      },
      "source": [
        "## <span style=\"color:green\">1.Datasets Tensorflow </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a1ed8c-b0f7-4433-b421-96dfe612ca3c",
      "metadata": {
        "id": "a6a1ed8c-b0f7-4433-b421-96dfe612ca3c"
      },
      "outputs": [],
      "source": [
        "# Población(en miles) de los 17 estados con más personas de México.\n",
        "Mexico = [16992,9209,8348,8062,6583,6116,5784,5543,4748,4132,3769,3741,3540,3527,3146,3082,3026]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42cf3928-e84c-4e01-a47a-515c8323fe08",
      "metadata": {
        "id": "42cf3928-e84c-4e01-a47a-515c8323fe08",
        "outputId": "25fda7b2-8a2c-439a-cfd5-c46555da7c32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-09 19:21:10.262257: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#Ármate un dataset desde la lista anterior\n",
        "dataset = tf.data.Dataset.from_tensor_slices(Mexico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244d3b3a-4056-418e-ba47-f79ff10945e8",
      "metadata": {
        "id": "244d3b3a-4056-418e-ba47-f79ff10945e8",
        "outputId": "c02fb33e-b61a-4af0-bc84-761b2eddc706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(16992, shape=(), dtype=int32)\n",
            "tf.Tensor(9209, shape=(), dtype=int32)\n",
            "tf.Tensor(8348, shape=(), dtype=int32)\n",
            "tf.Tensor(8062, shape=(), dtype=int32)\n",
            "tf.Tensor(6583, shape=(), dtype=int32)\n",
            "tf.Tensor(6116, shape=(), dtype=int32)\n",
            "tf.Tensor(5784, shape=(), dtype=int32)\n",
            "tf.Tensor(5543, shape=(), dtype=int32)\n",
            "tf.Tensor(4748, shape=(), dtype=int32)\n",
            "tf.Tensor(4132, shape=(), dtype=int32)\n",
            "tf.Tensor(3769, shape=(), dtype=int32)\n",
            "tf.Tensor(3741, shape=(), dtype=int32)\n",
            "tf.Tensor(3540, shape=(), dtype=int32)\n",
            "tf.Tensor(3527, shape=(), dtype=int32)\n",
            "tf.Tensor(3146, shape=(), dtype=int32)\n",
            "tf.Tensor(3082, shape=(), dtype=int32)\n",
            "tf.Tensor(3026, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "#Itera sobre el dataset\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29641b7-e94c-4795-82cc-149cbb5a8351",
      "metadata": {
        "id": "c29641b7-e94c-4795-82cc-149cbb5a8351"
      },
      "source": [
        "### <span style=\"color:blue\">1.1 Encadenar Transformaciones</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce998fde-d594-4153-bc5c-9728e36934e3",
      "metadata": {
        "id": "ce998fde-d594-4153-bc5c-9728e36934e3"
      },
      "outputs": [],
      "source": [
        "#Repite el dataset 2 veces y muéstralo en baches de 10, muestra tus resultados\n",
        "dataset = dataset.repeat(2).batch(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c7b16c5-348e-4b6a-8b15-712e7d7fcdae",
      "metadata": {
        "id": "0c7b16c5-348e-4b6a-8b15-712e7d7fcdae",
        "outputId": "dc9c6dca-f8c0-4170-e8ac-aa1ba10fae58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([16992  9209  8348  8062  6583  6116  5784  5543  4748  4132], shape=(10,), dtype=int32)\n",
            "tf.Tensor([ 3769  3741  3540  3527  3146  3082  3026 16992  9209  8348], shape=(10,), dtype=int32)\n",
            "tf.Tensor([8062 6583 6116 5784 5543 4748 4132 3769 3741 3540], shape=(10,), dtype=int32)\n",
            "tf.Tensor([3527 3146 3082 3026], shape=(4,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "#Visualiza el resultado\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0193ca72-121d-4a52-ab2c-7349dd5b6c91",
      "metadata": {
        "id": "0193ca72-121d-4a52-ab2c-7349dd5b6c91"
      },
      "outputs": [],
      "source": [
        "#Usa map y lambada para multiplicar todas las poblaciones por 1000\n",
        "dataset = dataset.map(lambda x: x*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48bbfed-0eca-47c4-9c52-0ee8c05355a8",
      "metadata": {
        "id": "f48bbfed-0eca-47c4-9c52-0ee8c05355a8",
        "outputId": "b74c36e4-f2b0-4cf9-f3ad-4e76a30bc5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([33984 18418 16696 16124 13166 12232 11568 11086  9496  8264], shape=(10,), dtype=int32)\n",
            "tf.Tensor([ 7538  7482  7080  7054  6292  6164  6052 33984 18418 16696], shape=(10,), dtype=int32)\n",
            "tf.Tensor([16124 13166 12232 11568 11086  9496  8264  7538  7482  7080], shape=(10,), dtype=int32)\n",
            "tf.Tensor([7054 6292 6164 6052], shape=(4,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "#Imprime resultados\n",
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab3b635e-3009-464d-aca8-9e6de5b666a1",
      "metadata": {
        "id": "ab3b635e-3009-464d-aca8-9e6de5b666a1"
      },
      "outputs": [],
      "source": [
        "#Convierte cada dato a su propio tensor (en vez de tener baches de 10 tensores)\n",
        "dataset = dataset.unbatch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5b3d12-6520-4dfc-b328-0aa783e7d63d",
      "metadata": {
        "id": "7d5b3d12-6520-4dfc-b328-0aa783e7d63d",
        "outputId": "5b78e370-2456-43aa-ae3c-c1624620df79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(33984, shape=(), dtype=int32)\n",
            "tf.Tensor(18418, shape=(), dtype=int32)\n",
            "tf.Tensor(16696, shape=(), dtype=int32)\n",
            "tf.Tensor(16124, shape=(), dtype=int32)\n",
            "tf.Tensor(13166, shape=(), dtype=int32)\n",
            "tf.Tensor(12232, shape=(), dtype=int32)\n",
            "tf.Tensor(11568, shape=(), dtype=int32)\n",
            "tf.Tensor(11086, shape=(), dtype=int32)\n",
            "tf.Tensor(9496, shape=(), dtype=int32)\n",
            "tf.Tensor(8264, shape=(), dtype=int32)\n",
            "tf.Tensor(7538, shape=(), dtype=int32)\n",
            "tf.Tensor(7482, shape=(), dtype=int32)\n",
            "tf.Tensor(7080, shape=(), dtype=int32)\n",
            "tf.Tensor(7054, shape=(), dtype=int32)\n",
            "tf.Tensor(6292, shape=(), dtype=int32)\n",
            "tf.Tensor(6164, shape=(), dtype=int32)\n",
            "tf.Tensor(6052, shape=(), dtype=int32)\n",
            "tf.Tensor(33984, shape=(), dtype=int32)\n",
            "tf.Tensor(18418, shape=(), dtype=int32)\n",
            "tf.Tensor(16696, shape=(), dtype=int32)\n",
            "tf.Tensor(16124, shape=(), dtype=int32)\n",
            "tf.Tensor(13166, shape=(), dtype=int32)\n",
            "tf.Tensor(12232, shape=(), dtype=int32)\n",
            "tf.Tensor(11568, shape=(), dtype=int32)\n",
            "tf.Tensor(11086, shape=(), dtype=int32)\n",
            "tf.Tensor(9496, shape=(), dtype=int32)\n",
            "tf.Tensor(8264, shape=(), dtype=int32)\n",
            "tf.Tensor(7538, shape=(), dtype=int32)\n",
            "tf.Tensor(7482, shape=(), dtype=int32)\n",
            "tf.Tensor(7080, shape=(), dtype=int32)\n",
            "tf.Tensor(7054, shape=(), dtype=int32)\n",
            "tf.Tensor(6292, shape=(), dtype=int32)\n",
            "tf.Tensor(6164, shape=(), dtype=int32)\n",
            "tf.Tensor(6052, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667a4d34-5c33-4fa3-9775-42148d51ca6a",
      "metadata": {
        "id": "667a4d34-5c33-4fa3-9775-42148d51ca6a"
      },
      "outputs": [],
      "source": [
        "#Filtra todos los estados mayores a 5,000 de personas\n",
        "dataset = dataset.filter(lambda mexico: mexico > 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d13f024-d648-4d41-b78d-9d806d1273d8",
      "metadata": {
        "id": "8d13f024-d648-4d41-b78d-9d806d1273d8",
        "outputId": "ded05af2-51a6-440f-ef23-ba6987a6b99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(33984, shape=(), dtype=int32)\n",
            "tf.Tensor(18418, shape=(), dtype=int32)\n",
            "tf.Tensor(16696, shape=(), dtype=int32)\n",
            "tf.Tensor(16124, shape=(), dtype=int32)\n",
            "tf.Tensor(13166, shape=(), dtype=int32)\n",
            "tf.Tensor(12232, shape=(), dtype=int32)\n",
            "tf.Tensor(11568, shape=(), dtype=int32)\n",
            "tf.Tensor(11086, shape=(), dtype=int32)\n",
            "tf.Tensor(33984, shape=(), dtype=int32)\n",
            "tf.Tensor(18418, shape=(), dtype=int32)\n",
            "tf.Tensor(16696, shape=(), dtype=int32)\n",
            "tf.Tensor(16124, shape=(), dtype=int32)\n",
            "tf.Tensor(13166, shape=(), dtype=int32)\n",
            "tf.Tensor(12232, shape=(), dtype=int32)\n",
            "tf.Tensor(11568, shape=(), dtype=int32)\n",
            "tf.Tensor(11086, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efed1027-847a-4b20-9bf0-8b18de87144f",
      "metadata": {
        "id": "efed1027-847a-4b20-9bf0-8b18de87144f",
        "outputId": "f908dd6b-0484-4549-c8b5-ad1bea0b4b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(33984, shape=(), dtype=int32)\n",
            "tf.Tensor(18418, shape=(), dtype=int32)\n",
            "tf.Tensor(16696, shape=(), dtype=int32)\n",
            "tf.Tensor(16124, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "#Usa Take para extraer los primeros 4 estados de tu lista\n",
        "for item in dataset.take(4):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "336d8c12-7487-46c5-aa10-cf53bd93c9e2",
      "metadata": {
        "id": "336d8c12-7487-46c5-aa10-cf53bd93c9e2"
      },
      "source": [
        "### <span style=\"color:blue\">1.2 Barajar los Resultados</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2ac0ba-677c-4d87-82f4-2b587ea6900f",
      "metadata": {
        "id": "ad2ac0ba-677c-4d87-82f4-2b587ea6900f"
      },
      "outputs": [],
      "source": [
        "#Vuelve a cargar los estados originales, repitelos 3 veces, y barajealos con un buffer de 8 y una semilla de 42, baches de 3\n",
        "dataset = tf.data.Dataset.from_tensor_slices(Mexico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113d05a8-3f74-4bb7-bf53-aee0b0867e82",
      "metadata": {
        "id": "113d05a8-3f74-4bb7-bf53-aee0b0867e82"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.repeat(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4633d27-faf5-44ef-b202-57da66e4a4d4",
      "metadata": {
        "id": "c4633d27-faf5-44ef-b202-57da66e4a4d4"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(buffer_size = 8, seed = 42).batch(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2de4568-22cc-41c6-96fd-26ecae33a046",
      "metadata": {
        "id": "d2de4568-22cc-41c6-96fd-26ecae33a046",
        "outputId": "a3926cdf-b658-48e5-af4c-03e7e045b54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([8062 5543 9209], shape=(3,), dtype=int32)\n",
            "tf.Tensor([5784 3769 4132], shape=(3,), dtype=int32)\n",
            "tf.Tensor([8348 4748 3540], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3082 3741 9209], shape=(3,), dtype=int32)\n",
            "tf.Tensor([16992 16992  6583], shape=(3,), dtype=int32)\n",
            "tf.Tensor([6116 3146 3026], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3527 6583 5543], shape=(3,), dtype=int32)\n",
            "tf.Tensor([8348 4748 8062], shape=(3,), dtype=int32)\n",
            "tf.Tensor([4132 3527 3026], shape=(3,), dtype=int32)\n",
            "tf.Tensor([5784 3741 3146], shape=(3,), dtype=int32)\n",
            "tf.Tensor([ 3082  9209 16992], shape=(3,), dtype=int32)\n",
            "tf.Tensor([8062 5543 3769], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3540 3769 5784], shape=(3,), dtype=int32)\n",
            "tf.Tensor([4132 8348 4748], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3741 6116 3146], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3540 3082 3026], shape=(3,), dtype=int32)\n",
            "tf.Tensor([3527 6116 6583], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e60bcc57-760f-40f2-9ccb-a0bce0e5173f",
      "metadata": {
        "id": "e60bcc57-760f-40f2-9ccb-a0bce0e5173f"
      },
      "source": [
        "### Ahora veamos el ejemplo con el Dataset de casas en California"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e05e066-94e8-45eb-9951-eb17d66c17d4",
      "metadata": {
        "id": "4e05e066-94e8-45eb-9951-eb17d66c17d4"
      },
      "outputs": [],
      "source": [
        "# Carga los datos de california, traintestsplit y standardscaler\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebaf2ea-aabb-4c81-a895-b5da771f2035",
      "metadata": {
        "id": "3ebaf2ea-aabb-4c81-a895-b5da771f2035"
      },
      "outputs": [],
      "source": [
        "# Carga los datos de california a variables xtrain y xtest\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a75057-e75b-4f2e-97cb-e3eb8d54338c",
      "metadata": {
        "id": "d6a75057-e75b-4f2e-97cb-e3eb8d54338c"
      },
      "outputs": [],
      "source": [
        "# Aplica el scaler y saca mean y std\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb8417b-e82d-4967-94da-554fdeff6ec4",
      "metadata": {
        "id": "fbb8417b-e82d-4967-94da-554fdeff6ec4"
      },
      "outputs": [],
      "source": [
        "# Vamos a separar el dataset en 20 pequeños archivos CSV - primero definimos una función para esto\n",
        "def save_to_multiple_csv_files(data,name_prefix, header=None, n_parts = 10):\n",
        "    housing_dir = os.path.join(\"datasets\",\"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m),n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a7c653-348b-4878-a88a-d33a83d00edd",
      "metadata": {
        "id": "25a7c653-348b-4878-a88a-d33a83d00edd"
      },
      "outputs": [],
      "source": [
        "# Ahora seapramos nuestros datos\n",
        "train_data = np.c_[X_train,y_train]\n",
        "valid_data = np.c_[X_valid,y_valid]\n",
        "test_data = np.c_[X_test,y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d24c07-14e0-4892-8abb-f663777e4c15",
      "metadata": {
        "id": "59d24c07-14e0-4892-8abb-f663777e4c15"
      },
      "outputs": [],
      "source": [
        "#Preparar los headers\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da49cdd6-f4ae-4ea3-accc-770cf61ed244",
      "metadata": {
        "id": "da49cdd6-f4ae-4ea3-accc-770cf61ed244",
        "outputId": "cbb18832-803b-4f2d-bea1-36ac2f488447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead2725f-2aa4-4d88-928b-5b6e3bc134c7",
      "metadata": {
        "id": "ead2725f-2aa4-4d88-928b-5b6e3bc134c7"
      },
      "outputs": [],
      "source": [
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts = 20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4998bce0-a6f7-42d7-a0be-48f0b7424919",
      "metadata": {
        "id": "4998bce0-a6f7-42d7-a0be-48f0b7424919",
        "outputId": "b482f7d3-c2d5-430a-bb17-2135cb4f96a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedianHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.5214</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.049945</td>\n",
              "      <td>1.106548</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>1.605993</td>\n",
              "      <td>37.63</td>\n",
              "      <td>-122.43</td>\n",
              "      <td>1.442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3275</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.490060</td>\n",
              "      <td>0.991054</td>\n",
              "      <td>3464.0</td>\n",
              "      <td>3.443340</td>\n",
              "      <td>33.69</td>\n",
              "      <td>-117.39</td>\n",
              "      <td>1.687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.1000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.542373</td>\n",
              "      <td>1.591525</td>\n",
              "      <td>1328.0</td>\n",
              "      <td>2.250847</td>\n",
              "      <td>38.44</td>\n",
              "      <td>-122.98</td>\n",
              "      <td>1.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.1736</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.289003</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>33.55</td>\n",
              "      <td>-117.70</td>\n",
              "      <td>2.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0549</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.312457</td>\n",
              "      <td>1.085092</td>\n",
              "      <td>3297.0</td>\n",
              "      <td>2.244384</td>\n",
              "      <td>33.93</td>\n",
              "      <td>-116.93</td>\n",
              "      <td>0.956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
              "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
              "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
              "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
              "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
              "\n",
              "   Longitude  MedianHouseValue  \n",
              "0    -122.43             1.442  \n",
              "1    -117.39             1.687  \n",
              "2    -122.98             1.621  \n",
              "3    -117.70             2.621  \n",
              "4    -116.93             0.956  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Veamos el resultado de uno de estos archivos\n",
        "import pandas as pd\n",
        "pd.read_csv(train_filepaths[0]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "030d3f78-48eb-490f-8053-dcc2e9605186",
      "metadata": {
        "id": "030d3f78-48eb-490f-8053-dcc2e9605186",
        "outputId": "d764c0d3-79d4-45a4-a36b-8ade0b6bf62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['datasets/housing/my_train_00.csv',\n",
              " 'datasets/housing/my_train_01.csv',\n",
              " 'datasets/housing/my_train_02.csv',\n",
              " 'datasets/housing/my_train_03.csv',\n",
              " 'datasets/housing/my_train_04.csv',\n",
              " 'datasets/housing/my_train_05.csv',\n",
              " 'datasets/housing/my_train_06.csv',\n",
              " 'datasets/housing/my_train_07.csv',\n",
              " 'datasets/housing/my_train_08.csv',\n",
              " 'datasets/housing/my_train_09.csv',\n",
              " 'datasets/housing/my_train_10.csv',\n",
              " 'datasets/housing/my_train_11.csv',\n",
              " 'datasets/housing/my_train_12.csv',\n",
              " 'datasets/housing/my_train_13.csv',\n",
              " 'datasets/housing/my_train_14.csv',\n",
              " 'datasets/housing/my_train_15.csv',\n",
              " 'datasets/housing/my_train_16.csv',\n",
              " 'datasets/housing/my_train_17.csv',\n",
              " 'datasets/housing/my_train_18.csv',\n",
              " 'datasets/housing/my_train_19.csv']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Veamos donde viven estos archivos\n",
        "train_filepaths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4336f5da-71dd-4829-8b09-b77a186473be",
      "metadata": {
        "id": "4336f5da-71dd-4829-8b09-b77a186473be"
      },
      "source": [
        "### <span style=\"color:blue\">1.3 Construyamos un pipeline de ingreso</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e34e7b6-355f-43bd-8ff4-2e1ce9da56e0",
      "metadata": {
        "id": "7e34e7b6-355f-43bd-8ff4-2e1ce9da56e0"
      },
      "outputs": [],
      "source": [
        "# Crea un objeto de filepath dataset\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed =42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b762aa-d80c-4748-bc7d-a9a6e096ca71",
      "metadata": {
        "id": "49b762aa-d80c-4748-bc7d-a9a6e096ca71",
        "outputId": "19af3c8d-17e1-411b-d8f1-58df0e6c35f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "#Checa los contenidos de tu nuevo dataset\n",
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80a5d3a-a4fa-4ac3-917f-12c6080156d0",
      "metadata": {
        "id": "b80a5d3a-a4fa-4ac3-917f-12c6080156d0"
      },
      "outputs": [],
      "source": [
        "#Vamos a leer de 5 archivos al mismo tiempo y mezclar sus lienas (saltandonos las primeras lienas de cada archivo)\n",
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length=n_readers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e253c340-a3c3-455b-8c3b-5cb4630c6400",
      "metadata": {
        "id": "e253c340-a3c3-455b-8c3b-5cb4630c6400",
        "outputId": "b160a347-3ef0-4d4a-8959-fba707cba1fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504'\n",
            "b'8.72,44.0,6.163179916317992,1.0460251046025104,668.0,2.794979079497908,34.2,-118.18,4.159'\n",
            "b'3.8456,35.0,5.461346633416459,0.9576059850374065,1154.0,2.8778054862842892,37.96,-122.05,1.598'\n",
            "b'3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526'\n",
            "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n"
          ]
        }
      ],
      "source": [
        "#Checamos resultados\n",
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e7ad93c-526e-48eb-b5bb-37f5216fa45f",
      "metadata": {
        "id": "7e7ad93c-526e-48eb-b5bb-37f5216fa45f"
      },
      "outputs": [],
      "source": [
        "#Hora de aplicar un parse (análisis gramatical) a nuestro dataset, comenzamos con una función que preprocesa nuestros datos:\n",
        "#1.- Primero tomamos una sola linea del CSV y la parseamos.\n",
        "#2.- Luego aplicamos tf.stack para amontonar todos nuestros tensores en un arreglo de 1D\n",
        "#3.- Finalmente, escalamos las variables de entrada y devolvemos una tupla que contiene las variables escaladas y el objetivo\n",
        "\n",
        "n_inputs = 8\n",
        "@tf.function\n",
        "\n",
        "def preprocess(line):\n",
        "    defs = [0.]*n_inputs + [tf.constant([],dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line,record_defaults = defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return(x-X_mean)/X_std,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60220121-bcaf-4255-bb37-6e6c2d0705d9",
      "metadata": {
        "id": "60220121-bcaf-4255-bb37-6e6c2d0705d9",
        "outputId": "c460f69a-9d18-451c-c9b8-48137e188c66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.39593136,  0.74167496, -0.16415128, -0.40340805, -0.61991787,\n",
              "        -0.18355484, -1.4084505 ,  1.2565969 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.504], dtype=float32)>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Ahora aplica la función a una línea para probarla\n",
        "preprocess(b'4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd7062e-eb8d-44b4-8240-d608301463fc",
      "metadata": {
        "id": "9bd7062e-eb8d-44b4-8240-d608301463fc"
      },
      "source": [
        "### <span style=\"color:blue\">1.4 Todo Junto a la Vez</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e31f62-ddcb-4da7-a58d-10acbae4faf5",
      "metadata": {
        "id": "82e31f62-ddcb-4da7-a58d-10acbae4faf5"
      },
      "outputs": [],
      "source": [
        "#Vamos a armar una sola función que haga todo lo que hicimos anteriormente.\n",
        "#Va a crear y devoler un dataset que cargará los datos de California de varios archivos de CSV, preprocesarlo, barajearlo, y bachearlo.\n",
        "def csv_reader_dataset(filepaths, repeat = 1, n_readers =5, n_read_threads=None, shuffle_buffer_size = 10000, n_parse_threads = 5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls = n_read_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8621eef0-8c8d-4786-8deb-bac56b5ad97f",
      "metadata": {
        "id": "8621eef0-8c8d-4786-8deb-bac56b5ad97f"
      },
      "outputs": [],
      "source": [
        "#Corre tu función sobre nuestra colección de csv, batch size de 3\n",
        "train_set = csv_reader_dataset(train_filepaths, batch_size = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57bc525f-fa65-4817-a58c-6ae8a4806763",
      "metadata": {
        "id": "57bc525f-fa65-4817-a58c-6ae8a4806763",
        "outputId": "7f3b1bdb-eb6b-4010-b076-d94483eff245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X =  tf.Tensor(\n",
            "[[ 1.1832466  -0.2867314   0.256955   -0.0914653   0.6741611   0.05366582\n",
            "  -0.7432092   0.71184903]\n",
            " [-0.44522637  1.8491895  -0.32066625 -0.14044929 -0.10611927 -0.06691425\n",
            "  -0.691678    0.7318402 ]\n",
            " [ 0.3091969   0.5043504   0.20859428 -0.2770272   0.6084533   0.27369827\n",
            "  -0.84627515  0.7818199 ]], shape=(3, 8), dtype=float32)\n",
            "y =  tf.Tensor(\n",
            "[[3.151]\n",
            " [2.226]\n",
            " [2.141]], shape=(3, 1), dtype=float32)\n",
            "\n",
            "X =  tf.Tensor(\n",
            "[[-1.2879554   1.4536486  -0.5052248   0.20396037 -0.49580315  0.43515173\n",
            "  -0.7666345   0.6568782 ]\n",
            " [-0.64608806 -1.0778131  -0.35905546  0.09489206  1.0309911  -0.22977838\n",
            "  -0.72447133  0.9767287 ]\n",
            " [ 1.7620009  -0.6822723   0.7482188  -0.23329605 -0.6326944  -0.32895038\n",
            "  -1.3241241   1.1716374 ]], shape=(3, 8), dtype=float32)\n",
            "y =  tf.Tensor(\n",
            "[[1.141]\n",
            " [1.228]\n",
            " [3.923]], shape=(3, 1), dtype=float32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Toma 2 baches y imprime sus valores X y y\n",
        "for X_batch, y_batch in train_set.take(2):\n",
        "    print(\"X = \", X_batch)\n",
        "    print(\"y = \", y_batch)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66470202-aa65-43a1-8f96-ccb56580fd38",
      "metadata": {
        "id": "66470202-aa65-43a1-8f96-ccb56580fd38"
      },
      "source": [
        "### <span style=\"color:blue\">1.5 Integrar esto en Keras</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52cde1a-caed-476a-bf75-2152f0fc88b0",
      "metadata": {
        "id": "b52cde1a-caed-476a-bf75-2152f0fc88b0"
      },
      "outputs": [],
      "source": [
        "#Carga tus datos mediante tu función en 3 sets - training, validación y prueba\n",
        "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5fad812-2530-45ff-92ba-82176cd2b79a",
      "metadata": {
        "id": "f5fad812-2530-45ff-92ba-82176cd2b79a"
      },
      "outputs": [],
      "source": [
        "#Despeja keras\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b168b22-20be-46ce-94fd-dd96dba33c4d",
      "metadata": {
        "id": "5b168b22-20be-46ce-94fd-dd96dba33c4d"
      },
      "outputs": [],
      "source": [
        "#Arma un modelo secuencial de 2 capas densas, 30 neuronas y 1 neurona respectivamente, activacion relu y su figura d eentrada\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a983a44-98d8-415c-bacd-617d079ee2ed",
      "metadata": {
        "id": "9a983a44-98d8-415c-bacd-617d079ee2ed"
      },
      "outputs": [],
      "source": [
        "#Compila con mse y SGD\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2016002a-f4dd-456f-b147-0c36d780b29d",
      "metadata": {
        "id": "2016002a-f4dd-456f-b147-0c36d780b29d",
        "outputId": "ae5990ca-dcea-4efd-c052-51e59ead32ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 1.9369 - val_loss: 1.1833\n",
            "Epoch 2/10\n",
            "362/362 [==============================] - 3s 7ms/step - loss: 0.6851 - val_loss: 1.3781\n",
            "Epoch 3/10\n",
            "362/362 [==============================] - 2s 5ms/step - loss: 0.6431 - val_loss: 0.6588\n",
            "Epoch 4/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.6551 - val_loss: 0.5915\n",
            "Epoch 5/10\n",
            "362/362 [==============================] - 2s 7ms/step - loss: 0.6097 - val_loss: 0.7647\n",
            "Epoch 6/10\n",
            "362/362 [==============================] - 1s 4ms/step - loss: 0.5584 - val_loss: 0.6040\n",
            "Epoch 7/10\n",
            "362/362 [==============================] - 1s 4ms/step - loss: 0.5412 - val_loss: 0.6749\n",
            "Epoch 8/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5223 - val_loss: 0.6188\n",
            "Epoch 9/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5154 - val_loss: 0.4912\n",
            "Epoch 10/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 0.5143\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe3cb081100>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejecuta en baches de 32, 10 epocas\n",
        "batch_size = 32\n",
        "model.fit(train_set, steps_per_epoch = len(X_train)//batch_size, epochs = 10, validation_data = valid_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e83f8e-10a6-42a3-8fdd-634e8336ab2b",
      "metadata": {
        "id": "52e83f8e-10a6-42a3-8fdd-634e8336ab2b",
        "outputId": "7627388f-0113-40fb-9285-73d226baed54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "161/161 [==============================] - 1s 2ms/step - loss: 0.4808\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4808122515678406"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Evalua el resultado\n",
        "model.evaluate(test_set, steps=len(X_test) // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f48af2c-315b-4804-9b0d-9e38a2174571",
      "metadata": {
        "id": "5f48af2c-315b-4804-9b0d-9e38a2174571"
      },
      "source": [
        "## <span style=\"color:green\">2.Pipeline de Imágenes </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1e042e-b7d8-40e5-838f-e56721c392a1",
      "metadata": {
        "id": "2d1e042e-b7d8-40e5-838f-e56721c392a1"
      },
      "outputs": [],
      "source": [
        "#Guarda la Lista de archivos de tus imágenes\n",
        "images_ds=tf.data.Dataset.list_files(\"HotDogs/*/*\", shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5beccd9-ac8c-44a4-9c91-2c4e09f19900",
      "metadata": {
        "id": "c5beccd9-ac8c-44a4-9c91-2c4e09f19900",
        "outputId": "ee4e44c6-5603-4f63-96ef-1ec0398ebb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'HotDogs/COMIDAS/00.jpg'\n",
            "b'HotDogs/COMIDAS/09.webp'\n",
            "b'HotDogs/COMIDAS/10.jpg'\n",
            "b'HotDogs/COMIDAS/11.jpg'\n",
            "b'HotDogs/COMIDAS/12.png'\n",
            "b'HotDogs/COMIDAS/13.webp'\n",
            "b'HotDogs/COMIDAS/14.webp'\n",
            "b'HotDogs/COMIDAS/17.jpg'\n",
            "b'HotDogs/COMIDAS/18.jpg'\n",
            "b'HotDogs/COMIDAS/19.jpg'\n"
          ]
        }
      ],
      "source": [
        "#Cuenta la cantidad de imágenes que existen+\n",
        "for file in images_ds.take(10):\n",
        "    print(file.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8610926d-e752-4672-9198-d604c5408a12",
      "metadata": {
        "id": "8610926d-e752-4672-9198-d604c5408a12",
        "outputId": "1fb9b477-5395-4dd3-fdab-2be48ebf9726"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Que tipo de dataset es tu archivo\n",
        "image_count = len(images_ds)\n",
        "image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f59905bb-1fb3-46d9-a251-c44cf54f3eb3",
      "metadata": {
        "id": "f59905bb-1fb3-46d9-a251-c44cf54f3eb3"
      },
      "outputs": [],
      "source": [
        "#Barajea tus imágenes\n",
        "images_ds = images_ds.shuffle(200)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enlace HotDogs\n",
        "[ENLACE](https://universidadsergioarboleda-my.sharepoint.com/:f:/g/personal/joaquin_sanchezc_usa_edu_co/EqHWOMQgzwpGgfbac__4nwkBl9Stgl0xNHPsFl9dm9KtIQ?e=Dkw2cF)"
      ],
      "metadata": {
        "id": "gb7oyZQ9uQvN"
      },
      "id": "gb7oyZQ9uQvN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3499c15-094d-4c61-a948-f48512c7fb3a",
      "metadata": {
        "id": "b3499c15-094d-4c61-a948-f48512c7fb3a",
        "outputId": "780c29ad-62dd-40a9-d92a-24b8d2f17d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'HotDogs/COMIDAS/87.jpg'\n",
            "b'HotDogs/COMIDAS/29.jpeg'\n",
            "b'HotDogs/COMIDAS/38.jpg'\n",
            "b'HotDogs/HOTDOGS/hots.webp'\n",
            "b'HotDogs/COMIDAS/53.jpg'\n",
            "b'HotDogs/COMIDAS/22.webp'\n",
            "b'HotDogs/HOTDOGS/p.webp'\n",
            "b'HotDogs/COMIDAS/26.jpg'\n",
            "b'HotDogs/COMIDAS/17.jpg'\n",
            "b'HotDogs/COMIDAS/33.htm'\n"
          ]
        }
      ],
      "source": [
        "#Toma 10 imágenes\n",
        "for file in images_ds.take(10):\n",
        "    print(file.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbac38c-4901-478f-8fa0-c8bbc689f0a8",
      "metadata": {
        "id": "2bbac38c-4901-478f-8fa0-c8bbc689f0a8"
      },
      "outputs": [],
      "source": [
        "#Ármate un set de entrenamiento y un set de prueba (80-20)\n",
        "train_size = int(image_count*.8)\n",
        "train_ds = images_ds.take(train_size)\n",
        "test_ds = images_ds.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7458bf-058f-45a4-8e64-508de86f216f",
      "metadata": {
        "id": "ea7458bf-058f-45a4-8e64-508de86f216f",
        "outputId": "92a320a7-0cf0-4272-9105-e9b3d580fd4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checa la longitud  de tus sets\n",
        "len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc920025-ffca-4aff-95f1-ee27801b637e",
      "metadata": {
        "id": "bc920025-ffca-4aff-95f1-ee27801b637e"
      },
      "outputs": [],
      "source": [
        "#Ahora vamos armando una funcion para traer las etiquetas\n",
        "def get_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    return parts[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2470b88-214b-4416-a56f-0f665caaeb85",
      "metadata": {
        "id": "b2470b88-214b-4416-a56f-0f665caaeb85",
        "outputId": "9d7e69ce-49f8-44dd-fc83-02c214929105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'HOTDOGS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n",
            "tf.Tensor(b'HOTDOGS', shape=(), dtype=string)\n",
            "tf.Tensor(b'HOTDOGS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n",
            "tf.Tensor(b'HOTDOGS', shape=(), dtype=string)\n",
            "tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "#Vamos probando tu función con una imagen\n",
        "for file in images_ds.take(10):\n",
        "    print(get_label(file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dcb884d-fc24-4349-824b-b9c73de8c7ad",
      "metadata": {
        "id": "0dcb884d-fc24-4349-824b-b9c73de8c7ad"
      },
      "outputs": [],
      "source": [
        "#Ahora armamos una función para procesar tus imágenes\n",
        "def process_image(file_path):\n",
        "    label = get_label(file_path)\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpg(img)\n",
        "    img = tf.image.resize(img, [128,128])\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cafd74c-fa4e-4693-b0fc-0caf6b33990a",
      "metadata": {
        "id": "9cafd74c-fa4e-4693-b0fc-0caf6b33990a"
      },
      "outputs": [],
      "source": [
        "#COrre tu función y guarda img y etiqueta\n",
        "img,label = process_image(\"HotDogs\\\\COMIDAS\\\\00.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0569751-3bbe-46e4-b205-a8730caaebba",
      "metadata": {
        "id": "c0569751-3bbe-46e4-b205-a8730caaebba",
        "outputId": "972d0cbd-6f30-4b93-850b-28eae76c77e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 128, 3), dtype=float32, numpy=\n",
              "array([[[2.52832031e+02, 2.51832031e+02, 2.47832031e+02],\n",
              "        [2.51437500e+02, 2.50437500e+02, 2.46437500e+02],\n",
              "        [2.52000000e+02, 2.52000000e+02, 2.50000000e+02],\n",
              "        ...,\n",
              "        [1.91591064e+02, 1.48591064e+02, 1.16591064e+02],\n",
              "        [1.81394531e+02, 1.43394531e+02, 1.07394531e+02],\n",
              "        [1.84683594e+02, 1.45683594e+02, 1.14683594e+02]],\n",
              "\n",
              "       [[2.54000000e+02, 2.54000000e+02, 2.52000000e+02],\n",
              "        [2.52000000e+02, 2.52000000e+02, 2.50000000e+02],\n",
              "        [2.53000000e+02, 2.52000000e+02, 2.47000000e+02],\n",
              "        ...,\n",
              "        [1.95441406e+02, 1.59937500e+02, 1.27937500e+02],\n",
              "        [1.90496094e+02, 1.54496094e+02, 1.22496094e+02],\n",
              "        [1.90086670e+02, 1.53086670e+02, 1.25078857e+02]],\n",
              "\n",
              "       [[2.52809814e+02, 2.52839844e+02, 2.50749756e+02],\n",
              "        [2.53839844e+02, 2.53749756e+02, 2.55000000e+02],\n",
              "        [2.54212646e+02, 2.49902344e+02, 2.39187500e+02],\n",
              "        ...,\n",
              "        [1.85732178e+02, 1.51732178e+02, 1.23732178e+02],\n",
              "        [1.88519531e+02, 1.53519531e+02, 1.23519531e+02],\n",
              "        [1.84157471e+02, 1.49157471e+02, 1.19157471e+02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[2.36130127e+02, 2.28522217e+02, 2.17899658e+02],\n",
              "        [2.36827637e+02, 2.20722656e+02, 1.89874756e+02],\n",
              "        [2.39062500e+02, 2.25777344e+02, 2.10080322e+02],\n",
              "        ...,\n",
              "        [7.93750000e+00, 3.93750000e+00, 9.37500000e-01],\n",
              "        [9.00000000e+00, 4.00000000e+00, 0.00000000e+00],\n",
              "        [1.54777832e+01, 6.47778320e+00, 1.60156250e-01]],\n",
              "\n",
              "       [[2.30409424e+02, 2.31502441e+02, 2.33223389e+02],\n",
              "        [2.28212646e+02, 2.11862793e+02, 1.78167480e+02],\n",
              "        [2.39441895e+02, 2.20843994e+02, 1.80734863e+02],\n",
              "        ...,\n",
              "        [7.00000000e+00, 3.00000000e+00, 0.00000000e+00],\n",
              "        [1.10585938e+01, 6.05859375e+00, 2.05859375e+00],\n",
              "        [2.41210938e+01, 1.51210938e+01, 8.12109375e+00]],\n",
              "\n",
              "       [[2.33000000e+02, 2.27000000e+02, 2.28625000e+02],\n",
              "        [2.23721924e+02, 2.15721924e+02, 1.93596924e+02],\n",
              "        [2.40812500e+02, 2.25812500e+02, 1.85002441e+02],\n",
              "        ...,\n",
              "        [8.00000000e+00, 4.00000000e+00, 3.00000000e+00],\n",
              "        [1.69790039e+01, 1.29790039e+01, 3.97900391e+00],\n",
              "        [2.22185059e+01, 1.32185059e+01, 4.96850586e+00]]], dtype=float32)>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b80e85-98e5-4885-86f1-d809777520f5",
      "metadata": {
        "id": "28b80e85-98e5-4885-86f1-d809777520f5"
      },
      "outputs": [],
      "source": [
        "#Revisemos el numpy de tu nuevo tensor donde están las imagenes guardadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c076b1aa-8de6-42d4-adaa-44482d1b1c95",
      "metadata": {
        "id": "c076b1aa-8de6-42d4-adaa-44482d1b1c95"
      },
      "outputs": [],
      "source": [
        "#Set de prueba y set de entrenamiento (mapea estos datos)\n",
        "train_ds = train_ds.map(process_image)\n",
        "test_ds = test_ds.map(process_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e887162-1d5b-4c5b-ae04-a103a2517413",
      "metadata": {
        "id": "0e887162-1d5b-4c5b-ae04-a103a2517413",
        "outputId": "6539701b-4afd-48f8-9f5e-4fb4ecca2f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image tf.Tensor(\n",
            "[[[ 11.  14.  65.]\n",
            "  [ 15.  20.  75.]\n",
            "  [ 12.  17.  57.]\n",
            "  ...\n",
            "  [150. 251. 237.]\n",
            "  [181. 253. 249.]\n",
            "  [224. 254. 254.]]\n",
            "\n",
            " [[ 16.  19.  72.]\n",
            "  [ 16.  18.  66.]\n",
            "  [ 49.  57.  94.]\n",
            "  ...\n",
            "  [194. 254. 246.]\n",
            "  [241. 250. 255.]\n",
            "  [237. 253. 252.]]\n",
            "\n",
            " [[ 13.  17.  65.]\n",
            "  [ 15.  14.  54.]\n",
            "  [ 14.  22.  68.]\n",
            "  ...\n",
            "  [232. 254. 252.]\n",
            "  [206. 255. 249.]\n",
            "  [165. 251. 242.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 87. 171. 156.]\n",
            "  [ 87. 171. 156.]\n",
            "  [ 84. 168. 153.]\n",
            "  ...\n",
            "  [165. 223. 173.]\n",
            "  [166. 225. 179.]\n",
            "  [171. 228. 185.]]\n",
            "\n",
            " [[ 85. 169. 153.]\n",
            "  [ 75. 159. 144.]\n",
            "  [ 86. 170. 157.]\n",
            "  ...\n",
            "  [180. 236. 187.]\n",
            "  [172. 229. 186.]\n",
            "  [164. 229. 197.]]\n",
            "\n",
            " [[ 79. 164. 145.]\n",
            "  [ 85. 169. 154.]\n",
            "  [ 79. 162. 152.]\n",
            "  ...\n",
            "  [177. 233. 184.]\n",
            "  [171. 226. 186.]\n",
            "  [158. 227. 206.]]], shape=(128, 128, 3), dtype=float32)\n",
            "Label tf.Tensor(b'COMIDAS', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "#Revisamos otra imagen en nuestro set de entrenamiento\n",
        "for image,label in train_ds.take(1):\n",
        "    print(\"Image\", image)\n",
        "    print(\"Label\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8986bf7f-0163-4a17-8895-2b7accdcc08c",
      "metadata": {
        "id": "8986bf7f-0163-4a17-8895-2b7accdcc08c"
      },
      "outputs": [],
      "source": [
        "#Hay que hacer el scale de la imagen\n",
        "def scale(image,label):\n",
        "    return image/255, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff205e49-2899-4d65-840c-dcdc9a6a484a",
      "metadata": {
        "id": "ff205e49-2899-4d65-840c-dcdc9a6a484a"
      },
      "outputs": [],
      "source": [
        "#Train ds con el scale aplicado\n",
        "train_ds = train_ds.map(scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f352f879-c8c3-4f6c-b2ce-2263e67fed06",
      "metadata": {
        "id": "f352f879-c8c3-4f6c-b2ce-2263e67fed06",
        "outputId": "ff171699-4714-47fe-e4b3-83de36bf6fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****Image:  [0.74969363 0.7143995  0.68694854]\n",
            "****Label:  b'COMIDAS'\n"
          ]
        }
      ],
      "source": [
        "#Checamos por óltimo nuestro set de datos con el scale aplicado\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"****Image: \",image.numpy()[0][0])\n",
        "    print(\"****Label: \",label.numpy())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}